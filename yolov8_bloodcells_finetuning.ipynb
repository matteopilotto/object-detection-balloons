{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "import ast\n",
    "import pybboxes as pbx\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import wandb\n",
    "\n",
    "import random\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"object-detection-yolov8\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"yolov8_bloodcells_finetuning.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.yolo.utils.torch_utils import get_flops, get_num_params\n",
    "\n",
    "# try:\n",
    "#     import wandb\n",
    "\n",
    "#     assert hasattr(wandb, '__version__')\n",
    "# except (ImportError, AssertionError):\n",
    "#     wandb = None\n",
    "\n",
    "\n",
    "def on_pretrain_routine_start(trainer):\n",
    "    wandb.init(\n",
    "        project=trainer.args.project or \"YOLOv8\", \n",
    "        name=trainer.args.name, \n",
    "        save_code=True,\n",
    "        config=dict(trainer.args)\n",
    "    ) if not wandb.run else wandb.run\n",
    "\n",
    "\n",
    "def on_fit_epoch_end(trainer):\n",
    "    wandb.run.log(trainer.metrics, step=trainer.epoch + 1)\n",
    "\n",
    "    if trainer.epoch == 0:\n",
    "        model_info = {\n",
    "            \"model/parameters\": get_num_params(trainer.model),\n",
    "            \"model/GFLOPs\": round(get_flops(trainer.model), 3),\n",
    "            \"model/speed(ms)\": round(sum(trainer.validator.speed.values()), 3)\n",
    "        }\n",
    "        wandb.run.log(model_info, step=trainer.epoch + 1)\n",
    "\n",
    "\n",
    "def on_train_epoch_end(trainer):\n",
    "    wandb.run.log(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=trainer.epoch + 1)\n",
    "    wandb.run.log(trainer.lr, step=trainer.epoch + 1)\n",
    "    if trainer.epoch == 1:\n",
    "        wandb.run.log({f.stem: wandb.Image(str(f)) for f in trainer.save_dir.glob('train_batch*.jpg')}, step=trainer.epoch + 1)\n",
    "\n",
    "\n",
    "def on_train_end(trainer):\n",
    "    art = wandb.Artifact(type=\"model\", name=f\"run_{wandb.run.id}_model\")\n",
    "    if trainer.best.exists():\n",
    "        art.add_file(trainer.best)\n",
    "        wandb.run.log_artifact(art)\n",
    "\n",
    "\n",
    "def on_predict_start(predictor):\n",
    "    wandb.init(\n",
    "        project=os.getenv(\"WANDB_PROJECT\"), \n",
    "        # name=predictor.args.name,\n",
    "        tags=[\"prediction\"],\n",
    "        save_code=True,\n",
    "        config=dict(predictor.args)\n",
    "    ) if not wandb.run else wandb.run\n",
    "\n",
    "def on_predict_end(predictor):\n",
    "    wandb.run.log({img_path.stem: wandb.Image(str(img_path)) for img_path in Path(predictor.save_dir).glob(\"*.jpg\")})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = {\n",
    "    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n",
    "    \"on_train_epoch_end\": on_train_epoch_end,\n",
    "    \"on_fit_epoch_end\": on_fit_epoch_end,\n",
    "    \"on_train_end\": on_train_end,\n",
    "    \"on_predict_start\": on_predict_start,\n",
    "    \"on_predict_end\": on_predict_end,\n",
    "} if wandb else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"keremberke/blood-cell-object-detection\", \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/workspace/object-detection-balloons/datasets/bloodcells\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -rf /workspace/object-detection-balloons/datasets/bloodcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in dataset:\n",
    "    for row in dataset[split]:\n",
    "        img_path = Path(os.path.join(dataset_dir, \"images\", split, str(row[\"image_id\"])) + \".jpg\")\n",
    "        os.makedirs(img_path.parent, exist_ok=True)\n",
    "        row[\"image\"].save(img_path)\n",
    "        for bbox, category in zip(row[\"objects\"][\"bbox\"], row[\"objects\"][\"category\"]):\n",
    "            bbox_yolo = pbx.convert_bbox(bbox, from_type=\"coco\", to_type=\"yolo\", image_size=(row[\"width\"], row[\"height\"]))\n",
    "            bbox_yolo = \" \".join([str(bb) for bb in bbox_yolo])\n",
    "            file_path = Path(os.path.join(dataset_dir, \"labels\", split, str(row[\"image_id\"])) + \".txt\")\n",
    "            os.makedirs(file_path.parent, exist_ok=True)\n",
    "            with open(file_path, \"a\") as f:\n",
    "                f.write(f\"{category} {bbox_yolo}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.170 ðŸš€ Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla V100-FHHL-16GB, 16151MiB)\n",
      "Setup complete âœ… (32 CPUs, 94.3 GB RAM, 1.2/20.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/object-detection-balloons/datasets/bloodcells/images/validation/51.jpg', '/workspace/object-detection-balloons/datasets/bloodcells/images/validation/14.jpg', '/workspace/object-detection-balloons/datasets/bloodcells/images/validation/48.jpg']\n",
      "['/workspace/object-detection-balloons/datasets/bloodcells/images/test/10.jpg', '/workspace/object-detection-balloons/datasets/bloodcells/images/test/32.jpg', '/workspace/object-detection-balloons/datasets/bloodcells/images/test/34.jpg']\n"
     ]
    }
   ],
   "source": [
    "val_img_base_path = \"/workspace/object-detection-balloons/datasets/bloodcells/images/validation\"\n",
    "val_img_paths = [os.path.join(val_img_base_path, fname) for fname in os.listdir(val_img_base_path)]\n",
    "print(val_img_paths[:3])\n",
    "\n",
    "test_img_base_path = \"/workspace/object-detection-balloons/datasets/bloodcells/images/test\"\n",
    "test_img_paths = [os.path.join(test_img_base_path, fname) for fname in os.listdir(test_img_base_path)]\n",
    "print(test_img_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'yolov8n.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/object-detection-balloons/wandb/run-20230904_062334-5uaa52do</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matt24/object-detection-yolov8/runs/5uaa52do' target=\"_blank\">lunar-glitter-6</a></strong> to <a href='https://wandb.ai/matt24/object-detection-yolov8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matt24/object-detection-yolov8' target=\"_blank\">https://wandb.ai/matt24/object-detection-yolov8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matt24/object-detection-yolov8/runs/5uaa52do' target=\"_blank\">https://wandb.ai/matt24/object-detection-yolov8/runs/5uaa52do</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 toothbrush, 1: 640x640 (no detections), 2: 640x640 1 person, 3: 640x640 1 teddy bear, 4: 640x640 1 person, 5: 640x640 (no detections), 6: 640x640 2 persons, 7: 640x640 (no detections), 8: 640x640 (no detections), 9: 640x640 (no detections), 10: 640x640 1 person, 11: 640x640 1 person, 12: 640x640 2 persons, 13: 640x640 (no detections), 14: 640x640 (no detections), 15: 640x640 1 person, 16: 640x640 (no detections), 17: 640x640 (no detections), 18: 640x640 1 person, 1 sports ball, 19: 640x640 1 person, 20: 640x640 1 toothbrush, 21: 640x640 1 person, 22: 640x640 (no detections), 23: 640x640 1 toothbrush, 24: 640x640 1 person, 1 toothbrush, 25: 640x640 1 donut, 26: 640x640 2 persons, 27: 640x640 (no detections), 28: 640x640 (no detections), 29: 640x640 (no detections), 30: 640x640 2 sports balls, 1 toothbrush, 31: 640x640 1 donut, 32: 640x640 1 sports ball, 33: 640x640 1 person, 1 sports ball, 34: 640x640 (no detections), 35: 640x640 (no detections), 36: 640x640 (no detections), 37: 640x640 1 donut, 38: 640x640 1 cake, 39: 640x640 1 donut, 40: 640x640 (no detections), 41: 640x640 (no detections), 42: 640x640 1 donut, 43: 640x640 (no detections), 44: 640x640 1 toothbrush, 45: 640x640 (no detections), 46: 640x640 (no detections), 47: 640x640 (no detections), 48: 640x640 1 person, 1 sports ball, 49: 640x640 1 sports ball, 50: 640x640 2 sports balls, 51: 640x640 1 sports ball, 52: 640x640 (no detections), 53: 640x640 1 donut, 1 toothbrush, 54: 640x640 1 toothbrush, 55: 640x640 (no detections), 56: 640x640 2 toothbrushs, 57: 640x640 1 sports ball, 58: 640x640 (no detections), 59: 640x640 (no detections), 60: 640x640 1 toothbrush, 61: 640x640 2 sports balls, 62: 640x640 1 toothbrush, 63: 640x640 1 toothbrush, 64: 640x640 (no detections), 65: 640x640 (no detections), 66: 640x640 1 sports ball, 67: 640x640 (no detections), 68: 640x640 (no detections), 69: 640x640 (no detections), 70: 640x640 1 sports ball, 1 toothbrush, 71: 640x640 (no detections), 72: 640x640 1 sports ball, 101.2ms\n",
      "Speed: 2.0ms preprocess, 1.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mpreds/baseline17\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "wandb: Network error (SSLError), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-glitter-6</strong> at: <a href='https://wandb.ai/matt24/object-detection-yolov8/runs/5uaa52do' target=\"_blank\">https://wandb.ai/matt24/object-detection-yolov8/runs/5uaa52do</a><br/> View job at <a href='https://wandb.ai/matt24/object-detection-yolov8/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk0ODQyMTk4/version_details/v2' target=\"_blank\">https://wandb.ai/matt24/object-detection-yolov8/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjk0ODQyMTk4/version_details/v2</a><br/>Synced 6 W&B file(s), 73 media file(s), 5 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230904_062334-5uaa52do/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yolo_base = YOLO(checkpoint)\n",
    "\n",
    "for cb_name, fb_fn in callbacks.items():\n",
    "    yolo_base.add_callback(cb_name, fb_fn)\n",
    "\n",
    "preds = yolo_base.predict(val_img_paths, save=True, project=\"preds\", name=\"baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_finetuned = YOLO(checkpoint)  # load a pretrained model (recommended for training)\n",
    "for cb_name, cb_fn in callbacks.items():\n",
    "    yolo_finetuned.add_callback(cb_name, cb_fn)\n",
    "\n",
    "dataset_yaml_path = \"/workspace/object-detection-balloons/bloodcells.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.168 ðŸš€ Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla V100-FHHL-16GB, 16151MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/workspace/object-detection-balloons/bloodcells.yaml, epochs=50, patience=50, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3777433  ultralytics.nn.modules.head.Detect           [3, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25858057 parameters, 25858041 gradients\n",
      "\n",
      "Transferred 475/475 items from pretrained weights\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 1160, in init\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\", line 189, in setup\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 114, in __init__\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 250, in _setup\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py\", line 277, in _setup_manager\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py\", line 130, in __init__\n",
      "ModuleNotFoundError: No module named 'wandb.sdk.service'\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "An unexpected error occurred",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py:1160\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py:189\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:327\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(settings)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:320\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(settings, _reset)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:303\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, settings)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:114\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, pid, settings, environ)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:250\u001b[0m, in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_setup.py:277\u001b[0m, in \u001b[0;36m_setup_manager\u001b[0;34m(self)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_manager.py:130\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, settings)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb.sdk.service'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Use the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m yolo_finetuned\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49mdataset_yaml_path, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)  \u001b[39m# train the model\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py:341\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    342\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:196\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:294\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39mif\u001b[39;00m world_size \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 294\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_train(world_size)\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:216\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39mBuilds dataloaders and optimizer on correct rank process.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m# Model\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_callbacks(\u001b[39m'\u001b[39;49m\u001b[39mon_pretrain_routine_start\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    217\u001b[0m ckpt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup_model()\n\u001b[1;32m    218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py:161\u001b[0m, in \u001b[0;36mBaseTrainer.run_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mget(event, []):\n\u001b[0;32m--> 161\u001b[0m     callback(\u001b[39mself\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mon_pretrain_routine_start\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_pretrain_routine_start\u001b[39m(trainer):\n\u001b[0;32m---> 12\u001b[0m     wandb\u001b[39m.\u001b[39;49minit(project\u001b[39m=\u001b[39;49mtrainer\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mproject \u001b[39mor\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mYOLOv8\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     13\u001b[0m                name\u001b[39m=\u001b[39;49mtrainer\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mname, \n\u001b[1;32m     14\u001b[0m                save_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     15\u001b[0m                config\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m     16\u001b[0m         trainer\u001b[39m.\u001b[39;49margs)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wandb\u001b[39m.\u001b[39mrun \u001b[39melse\u001b[39;00m wandb\u001b[39m.\u001b[39mrun\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py:1202\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: An unexpected error occurred"
     ]
    }
   ],
   "source": [
    "# Use the model\n",
    "results = yolo_finetuned.train(data=dataset_yaml_path, epochs=50, batch=32)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 30 rbcs, 1 wbc, 1: 640x640 1 platelets, 15 rbcs, 1 wbc, 2: 640x640 2 plateletss, 29 rbcs, 1 wbc, 3: 640x640 1 platelets, 24 rbcs, 1 wbc, 4: 640x640 2 plateletss, 21 rbcs, 1 wbc, 5: 640x640 1 platelets, 29 rbcs, 1 wbc, 6: 640x640 15 rbcs, 1 wbc, 7: 640x640 2 plateletss, 14 rbcs, 1 wbc, 8: 640x640 17 rbcs, 1 wbc, 9: 640x640 3 plateletss, 23 rbcs, 1 wbc, 10: 640x640 1 platelets, 17 rbcs, 2 wbcs, 11: 640x640 1 platelets, 16 rbcs, 1 wbc, 12: 640x640 18 rbcs, 1 wbc, 13: 640x640 1 platelets, 20 rbcs, 1 wbc, 14: 640x640 5 plateletss, 23 rbcs, 1 wbc, 15: 640x640 1 platelets, 16 rbcs, 1 wbc, 16: 640x640 1 platelets, 18 rbcs, 1 wbc, 17: 640x640 1 platelets, 27 rbcs, 1 wbc, 18: 640x640 1 platelets, 27 rbcs, 1 wbc, 19: 640x640 1 platelets, 26 rbcs, 1 wbc, 20: 640x640 22 rbcs, 1 wbc, 21: 640x640 2 plateletss, 20 rbcs, 2 wbcs, 22: 640x640 23 rbcs, 1 wbc, 23: 640x640 23 rbcs, 1 wbc, 24: 640x640 1 platelets, 20 rbcs, 1 wbc, 25: 640x640 22 rbcs, 1 wbc, 26: 640x640 3 plateletss, 25 rbcs, 1 wbc, 27: 640x640 19 rbcs, 1 wbc, 28: 640x640 1 platelets, 20 rbcs, 1 wbc, 29: 640x640 1 platelets, 12 rbcs, 1 wbc, 30: 640x640 2 plateletss, 22 rbcs, 1 wbc, 31: 640x640 2 plateletss, 23 rbcs, 1 wbc, 32: 640x640 26 rbcs, 1 wbc, 33: 640x640 21 rbcs, 1 wbc, 34: 640x640 2 plateletss, 23 rbcs, 1 wbc, 35: 640x640 2 plateletss, 19 rbcs, 1 wbc, 36: 640x640 1 platelets, 22 rbcs, 1 wbc, 37: 640x640 1 platelets, 20 rbcs, 1 wbc, 38: 640x640 2 plateletss, 27 rbcs, 1 wbc, 39: 640x640 2 plateletss, 26 rbcs, 1 wbc, 40: 640x640 1 platelets, 22 rbcs, 1 wbc, 41: 640x640 2 plateletss, 27 rbcs, 1 wbc, 42: 640x640 3 plateletss, 24 rbcs, 1 wbc, 43: 640x640 4 plateletss, 25 rbcs, 1 wbc, 44: 640x640 2 plateletss, 24 rbcs, 1 wbc, 45: 640x640 2 plateletss, 19 rbcs, 1 wbc, 46: 640x640 19 rbcs, 1 wbc, 47: 640x640 1 platelets, 28 rbcs, 1 wbc, 48: 640x640 1 platelets, 23 rbcs, 1 wbc, 49: 640x640 2 plateletss, 31 rbcs, 1 wbc, 50: 640x640 3 plateletss, 20 rbcs, 1 wbc, 51: 640x640 1 platelets, 18 rbcs, 2 wbcs, 52: 640x640 3 plateletss, 21 rbcs, 1 wbc, 53: 640x640 2 plateletss, 22 rbcs, 1 wbc, 54: 640x640 1 platelets, 23 rbcs, 1 wbc, 55: 640x640 20 rbcs, 1 wbc, 56: 640x640 1 platelets, 18 rbcs, 1 wbc, 57: 640x640 1 platelets, 20 rbcs, 1 wbc, 58: 640x640 1 platelets, 19 rbcs, 1 wbc, 59: 640x640 1 platelets, 25 rbcs, 1 wbc, 60: 640x640 2 plateletss, 22 rbcs, 1 wbc, 61: 640x640 1 platelets, 22 rbcs, 1 wbc, 62: 640x640 26 rbcs, 1 wbc, 63: 640x640 3 plateletss, 27 rbcs, 1 wbc, 64: 640x640 1 platelets, 23 rbcs, 1 wbc, 65: 640x640 23 rbcs, 1 wbc, 66: 640x640 2 plateletss, 19 rbcs, 1 wbc, 67: 640x640 17 rbcs, 1 wbc, 68: 640x640 1 platelets, 17 rbcs, 1 wbc, 69: 640x640 1 platelets, 25 rbcs, 1 wbc, 70: 640x640 2 plateletss, 24 rbcs, 1 wbc, 71: 640x640 1 platelets, 23 rbcs, 1 wbc, 72: 640x640 4 plateletss, 26 rbcs, 1 wbc, 332.5ms\n",
      "Speed: 1.3ms preprocess, 4.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mpreds/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /workspace/object-detection-balloons/preds/val\n",
    "preds = yolo_finetuned.predict(val_img_paths, save=True, project=\"preds\", name=\"val\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 platelets, 25 rbcs, 1 wbc, 1: 640x640 3 plateletss, 24 rbcs, 2 wbcs, 2: 640x640 1 platelets, 22 rbcs, 1 wbc, 3: 640x640 4 plateletss, 16 rbcs, 1 wbc, 4: 640x640 2 plateletss, 25 rbcs, 1 wbc, 5: 640x640 2 plateletss, 27 rbcs, 1 wbc, 6: 640x640 1 platelets, 17 rbcs, 1 wbc, 7: 640x640 20 rbcs, 1 wbc, 8: 640x640 1 platelets, 23 rbcs, 1 wbc, 9: 640x640 3 plateletss, 16 rbcs, 2 wbcs, 10: 640x640 2 plateletss, 22 rbcs, 1 wbc, 11: 640x640 1 platelets, 16 rbcs, 1 wbc, 12: 640x640 1 platelets, 27 rbcs, 1 wbc, 13: 640x640 20 rbcs, 1 wbc, 14: 640x640 2 plateletss, 25 rbcs, 1 wbc, 15: 640x640 14 rbcs, 1 wbc, 16: 640x640 22 rbcs, 1 wbc, 17: 640x640 18 rbcs, 1 wbc, 18: 640x640 2 plateletss, 18 rbcs, 1 wbc, 19: 640x640 2 plateletss, 29 rbcs, 2 wbcs, 20: 640x640 1 platelets, 19 rbcs, 1 wbc, 21: 640x640 2 plateletss, 30 rbcs, 1 wbc, 22: 640x640 3 plateletss, 18 rbcs, 1 wbc, 23: 640x640 18 rbcs, 1 wbc, 24: 640x640 21 rbcs, 1 wbc, 25: 640x640 2 plateletss, 22 rbcs, 1 wbc, 26: 640x640 1 platelets, 23 rbcs, 1 wbc, 27: 640x640 2 plateletss, 21 rbcs, 1 wbc, 28: 640x640 21 rbcs, 1 wbc, 29: 640x640 26 rbcs, 1 wbc, 30: 640x640 29 rbcs, 1 wbc, 31: 640x640 11 rbcs, 1 wbc, 32: 640x640 1 platelets, 23 rbcs, 1 wbc, 33: 640x640 3 plateletss, 27 rbcs, 1 wbc, 34: 640x640 3 plateletss, 19 rbcs, 1 wbc, 35: 640x640 1 platelets, 17 rbcs, 1 wbc, 163.9ms\n",
      "Speed: 1.3ms preprocess, 4.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mpreds/test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /workspace/object-detection-balloons/preds/test\n",
    "preds = yolo_finetuned.predict(test_img_paths, save=True, project=\"preds\", name=\"test\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
